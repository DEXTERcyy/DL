{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget, os, gzip, pickle, random, re, sys\n",
    "\n",
    "IMDB_URL = 'http://dlvu.github.io/data/imdb.{}.pkl.gz'\n",
    "IMDB_FILE = 'imdb.{}.pkl.gz'\n",
    "\n",
    "PAD, START, END, UNK = '.pad', '.start', '.end', '.unk'\n",
    "\n",
    "def load_imdb(final=False, val=5000, seed=0, voc=None, char=False):\n",
    "\n",
    "    cst = 'char' if char else 'word'\n",
    "\n",
    "    imdb_url = IMDB_URL.format(cst)\n",
    "    imdb_file = IMDB_FILE.format(cst)\n",
    "\n",
    "    if not os.path.exists(imdb_file):\n",
    "        wget.download(imdb_url)\n",
    "\n",
    "    with gzip.open(imdb_file) as file:\n",
    "        sequences, labels, i2w, w2i = pickle.load(file)\n",
    "\n",
    "    if voc is not None and voc < len(i2w):\n",
    "        nw_sequences = {}\n",
    "\n",
    "        i2w = i2w[:voc]\n",
    "        w2i = {w: i for i, w in enumerate(i2w)}\n",
    "\n",
    "        mx, unk = voc, w2i['.unk']\n",
    "        for key, seqs in sequences.items():\n",
    "            nw_sequences[key] = []\n",
    "            for seq in seqs:\n",
    "                seq = [s if s < mx else unk for s in seq]\n",
    "                nw_sequences[key].append(seq)\n",
    "\n",
    "        sequences = nw_sequences\n",
    "\n",
    "    if final:\n",
    "        return (sequences['train'], labels['train']), (sequences['test'], labels['test']), (i2w, w2i), 2\n",
    "\n",
    "    # Make a validation split\n",
    "    random.seed(seed)\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    x_val, y_val = [], []\n",
    "\n",
    "    val_ind = set( random.sample(range(len(sequences['train'])), k=val) )\n",
    "    for i, (s, l) in enumerate(zip(sequences['train'], labels['train'])):\n",
    "        if i in val_ind:\n",
    "            x_val.append(s)\n",
    "            y_val.append(l)\n",
    "        else:\n",
    "            x_train.append(s)\n",
    "            y_train.append(l)\n",
    "\n",
    "    return (x_train, y_train), \\\n",
    "           (x_val, y_val), \\\n",
    "           (i2w, w2i), 2\n",
    "\n",
    "\n",
    "def gen_sentence(sent, g):\n",
    "\n",
    "    symb = '_[a-z]*'\n",
    "\n",
    "    while True:\n",
    "\n",
    "        match = re.search(symb, sent)\n",
    "        if match is None:\n",
    "            return sent\n",
    "\n",
    "        s = match.span()\n",
    "        sent = sent[:s[0]] + random.choice(g[sent[s[0]:s[1]]]) + sent[s[1]:]\n",
    "\n",
    "def gen_dyck(p):\n",
    "    open = 1\n",
    "    sent = '('\n",
    "    while open > 0:\n",
    "        if random.random() < p:\n",
    "            sent += '('\n",
    "            open += 1\n",
    "        else:\n",
    "            sent += ')'\n",
    "            open -= 1\n",
    "\n",
    "    return sent\n",
    "\n",
    "def gen_ndfa(p):\n",
    "\n",
    "    word = random.choice(['abc!', 'uvw!', 'klm!'])\n",
    "\n",
    "    s = ''\n",
    "    while True:\n",
    "        if random.random() < p:\n",
    "            return 's' + s + 's'\n",
    "        else:\n",
    "            s+= word\n",
    "\n",
    "def load_brackets(n=50_000, seed=0):\n",
    "    return load_toy(n, char=True, seed=seed, name='dyck')\n",
    "\n",
    "def load_ndfa(n=50_000, seed=0):\n",
    "    return load_toy(n, char=True, seed=seed, name='ndfa')\n",
    "\n",
    "def load_toy(n=50_000, char=True, seed=0, name='lang'):\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    if name == 'lang':\n",
    "        sent = '_s'\n",
    "\n",
    "        toy = {\n",
    "            '_s': ['_s _adv', '_np _vp', '_np _vp _prep _np', '_np _vp ( _prep _np )', '_np _vp _con _s' , '_np _vp ( _con _s )'],\n",
    "            '_adv': ['briefly', 'quickly', 'impatiently'],\n",
    "            '_np': ['a _noun', 'the _noun', 'a _adj _noun', 'the _adj _noun'],\n",
    "            '_prep': ['on', 'with', 'to'],\n",
    "            '_con' : ['while', 'but'],\n",
    "            '_noun': ['mouse', 'bunny', 'cat', 'dog', 'man', 'woman', 'person'],\n",
    "            '_vp': ['walked', 'walks', 'ran', 'runs', 'goes', 'went'],\n",
    "            '_adj': ['short', 'quick', 'busy', 'nice', 'gorgeous']\n",
    "        }\n",
    "\n",
    "        sentences = [ gen_sentence(sent, toy) for _ in range(n)]\n",
    "        sentences.sort(key=lambda s : len(s))\n",
    "\n",
    "    elif name == 'dyck':\n",
    "\n",
    "        sentences = [gen_dyck(7./16.) for _ in range(n)]\n",
    "        sentences.sort(key=lambda s: len(s))\n",
    "\n",
    "    elif name == 'ndfa':\n",
    "\n",
    "        sentences = [gen_ndfa(1./4.) for _ in range(n)]\n",
    "        sentences.sort(key=lambda s: len(s))\n",
    "\n",
    "    else:\n",
    "        raise Exception(name)\n",
    "\n",
    "    tokens = set()\n",
    "    for s in sentences:\n",
    "\n",
    "        if char:\n",
    "            for c in s:\n",
    "                tokens.add(c)\n",
    "        else:\n",
    "            for w in s.split():\n",
    "                tokens.add(w)\n",
    "\n",
    "    i2t = [PAD, START, END, UNK] + list(tokens)\n",
    "    t2i = {t:i for i, t in enumerate(i2t)}\n",
    "\n",
    "    sequences = []\n",
    "    for s in sentences:\n",
    "        if char:\n",
    "            tok = list(s)\n",
    "        else:\n",
    "            tok = s.split()\n",
    "        sequences.append([t2i[t] for t in tok])\n",
    "\n",
    "    return sequences, (i2t, t2i)\n",
    "(x_train, y_train), (x_val, y_val), (i2w, w2i), numcls = load_imdb(final=False)\n",
    "# x_train A python list of lists of integers. Each integer represents a word. Sorted from short to long.\n",
    "# i2w A list of strings mapping the integers in the sequences to their original words.\n",
    "# w2i A dictionary mapping the words to their indices. w2i['film'] returns the index for the word \"film\".\n",
    "# 0 -> positive, 1 -> negative\n",
    "# print(x_train[141][:5])\n",
    "# print([i2w[w] for w in x_train[141]])\n",
    "# print([w2i[i] for i in [i2w[w] for w in x_train[141]]][:5])\n",
    "# print(y_train[141])\n",
    "# print(numcls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def batch_padding(batch):\n",
    "    padded_batch = []; max_len = max(len(x) for x in batch)+2\n",
    "    for seq in batch:\n",
    "        seq = [w2i['.start']] + seq + [w2i['.end']]\n",
    "        if len(seq) < max_len:\n",
    "            seq += [w2i['.pad']] * (max_len - len(seq))\n",
    "        padded_batch.append(seq)\n",
    "    return torch.tensor(padded_batch, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Linear layer with ReLU activation\n",
    "        self.linear_relu = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Linear layer for binary classification\n",
    "        self.linear_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_text):\n",
    "        # Embedding layer\n",
    "        embedded = self.embedding(input_text)\n",
    "\n",
    "        # Linear layer with ReLU activation\n",
    "        linear_output = self.relu(self.linear_relu(embedded))\n",
    "\n",
    "        # Global max pooling layer\n",
    "        pooled_output, _ = torch.max(linear_output, dim=1)\n",
    "\n",
    "        # Linear layer for binary classification\n",
    "        output = self.linear_out(pooled_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 50, Epochs: 3, Learning rate: 0.001, Average_val_loss: 0.6319688534736634, Validation Accuracy: 0.6866\n",
      "Batch size: 50, Epochs: 3, Learning rate: 0.005, Average_val_loss: 0.465954367518425, Validation Accuracy: 0.7746\n",
      "Batch size: 50, Epochs: 3, Learning rate: 0.01, Average_val_loss: 0.736927616596222, Validation Accuracy: 0.6784\n",
      "Batch size: 50, Epochs: 5, Learning rate: 0.001, Average_val_loss: 0.6231666350364685, Validation Accuracy: 0.6940\n",
      "Batch size: 50, Epochs: 5, Learning rate: 0.005, Average_val_loss: 0.39970849856734275, Validation Accuracy: 0.8136\n",
      "Batch size: 50, Epochs: 5, Learning rate: 0.01, Average_val_loss: 0.493350368142128, Validation Accuracy: 0.7824\n",
      "Batch size: 50, Epochs: 7, Learning rate: 0.001, Average_val_loss: 0.5726725146174431, Validation Accuracy: 0.7190\n",
      "Batch size: 50, Epochs: 7, Learning rate: 0.005, Average_val_loss: 0.41256222277879717, Validation Accuracy: 0.8058\n",
      "Batch size: 50, Epochs: 7, Learning rate: 0.01, Average_val_loss: 0.3462300319969654, Validation Accuracy: 0.8506\n",
      "Batch size: 100, Epochs: 3, Learning rate: 0.001, Average_val_loss: 0.6534315574169159, Validation Accuracy: 0.6440\n",
      "Batch size: 100, Epochs: 3, Learning rate: 0.005, Average_val_loss: 0.5671027708053589, Validation Accuracy: 0.7150\n",
      "Batch size: 100, Epochs: 3, Learning rate: 0.01, Average_val_loss: 0.9565401041507721, Validation Accuracy: 0.5860\n",
      "Batch size: 100, Epochs: 5, Learning rate: 0.001, Average_val_loss: 0.6471119832992553, Validation Accuracy: 0.6500\n",
      "Batch size: 100, Epochs: 5, Learning rate: 0.005, Average_val_loss: 0.46200624585151673, Validation Accuracy: 0.7872\n",
      "Batch size: 100, Epochs: 5, Learning rate: 0.01, Average_val_loss: 0.4562406557798386, Validation Accuracy: 0.7844\n",
      "Batch size: 100, Epochs: 7, Learning rate: 0.001, Average_val_loss: 0.5981363475322723, Validation Accuracy: 0.7278\n",
      "Batch size: 100, Epochs: 7, Learning rate: 0.005, Average_val_loss: 0.4329436945915222, Validation Accuracy: 0.8000\n",
      "Batch size: 100, Epochs: 7, Learning rate: 0.01, Average_val_loss: 0.3513597047328949, Validation Accuracy: 0.8442\n",
      "Batch size: 200, Epochs: 3, Learning rate: 0.001, Average_val_loss: 0.6818029022216797, Validation Accuracy: 0.5584\n",
      "Batch size: 200, Epochs: 3, Learning rate: 0.005, Average_val_loss: 0.6603087186813354, Validation Accuracy: 0.5328\n",
      "Batch size: 200, Epochs: 3, Learning rate: 0.01, Average_val_loss: 1.6470994758605957, Validation Accuracy: 0.5008\n",
      "Batch size: 200, Epochs: 5, Learning rate: 0.001, Average_val_loss: 0.6728029561042785, Validation Accuracy: 0.5732\n",
      "Batch size: 200, Epochs: 5, Learning rate: 0.005, Average_val_loss: 0.5555780386924744, Validation Accuracy: 0.7242\n",
      "Batch size: 200, Epochs: 5, Learning rate: 0.01, Average_val_loss: 0.792051203250885, Validation Accuracy: 0.5904\n",
      "Batch size: 200, Epochs: 7, Learning rate: 0.001, Average_val_loss: 0.6606175684928894, Validation Accuracy: 0.6330\n",
      "Batch size: 200, Epochs: 7, Learning rate: 0.005, Average_val_loss: 0.5176939785480499, Validation Accuracy: 0.7546\n",
      "Batch size: 200, Epochs: 7, Learning rate: 0.01, Average_val_loss: 0.6329993963241577, Validation Accuracy: 0.6786\n",
      "Best parameters: {'batch_size': 50, 'epochs': 7, 'learning_rate': 0.01, 'average_val_loss': 0.3462300319969654, 'val_accuracy': 0.8506}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Apply GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "vocab_size = len(i2w)\n",
    "embedding_dim = 300\n",
    "hidden_size = 300\n",
    "output_dim = 2\n",
    "param_grid = {\n",
    "    'batch_size': [50, 100, 200],\n",
    "    'epochs': [3, 5, 7],\n",
    "    'learning_rate': [0.001, 0.005, 0.01]\n",
    "}\n",
    "\n",
    "# Create parameter grid\n",
    "grid = ParameterGrid(param_grid)\n",
    "results = []\n",
    "\n",
    "for params in grid:\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    learning_rate = params['learning_rate']\n",
    "# Instantiate the model and move it to the device\n",
    "    model = SimpleRNN(vocab_size, embedding_dim, hidden_size, output_dim).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() # combines nn.LogSoftmax() and nn.NLLLoss() in one.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        # create batch generators in steps of batch_size-1\n",
    "        x_train_gen = (x_train[i-batch_size:i] for i in range(batch_size, len(x_train), batch_size-1))\n",
    "        y_train_gen = (y_train[i-batch_size:i] for i in range(batch_size, len(y_train), batch_size-1))\n",
    "        \n",
    "        x_val_gen = (x_val[i-batch_size:i] for i in range(batch_size, len(x_val), batch_size-1))\n",
    "        y_val_gen = (y_val[i-batch_size:i] for i in range(batch_size, len(y_val), batch_size-1))\n",
    "        \n",
    "        # Loop over batches\n",
    "        for step in range(int(len(x_train)/batch_size)):\n",
    "            # Extract batch and perform padding\n",
    "            x_train_batch, y_train_batch = (batch_padding(next(x_train_gen)),\n",
    "                                            torch.tensor(next(y_train_gen), dtype=torch.long))\n",
    "            \n",
    "            # Move the data to the device\n",
    "            x_train_batch = x_train_batch.to(device)\n",
    "            y_train_batch = y_train_batch.to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(x_train_batch)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs.squeeze(), y_train_batch) # squeeze() removes the extra dimension\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / (len(x_train) / batch_size)\n",
    "        #print(f\"Epoch {epoch + 1}/{epochs}, Loss: {average_loss:.4f}\")\n",
    "        \n",
    "        # Model Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Turn of gradient for faster computation\n",
    "        with torch.no_grad():\n",
    "            for val_step in range(int(len(x_val)/batch_size)):\n",
    "                # Extract validation batches\n",
    "                x_val_batch, y_val_batch = (batch_padding(next(x_val_gen)),\n",
    "                                            torch.tensor(next(y_val_gen), dtype=torch.long))\n",
    "\n",
    "                # Move the data to the device\n",
    "                x_val_batch = x_val_batch.to(device)\n",
    "                y_val_batch = y_val_batch.to(device)\n",
    "\n",
    "                # Forward pass and compute loss\n",
    "                outputs = model(x_val_batch)\n",
    "                loss = criterion(outputs.squeeze(), y_val_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Compare predictions with ground-truth\n",
    "                predictions = torch.argmax(torch.softmax(outputs,1),dim=1)\n",
    "                correct_predictions += (predictions == y_val_batch).sum().item()\n",
    "                total_samples += y_val_batch.size(0)\n",
    "\n",
    "        average_val_loss = val_loss / (len(x_val) / batch_size)\n",
    "        val_accuracy = correct_predictions / total_samples\n",
    "        #print(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    results.append({\n",
    "        'batch_size': batch_size,\n",
    "        'epochs': epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'average_val_loss': average_val_loss,\n",
    "        'val_accuracy': val_accuracy\n",
    "    })\n",
    "    #print(f\"Batch size: {batch_size}, Epochs: {epochs}, Learning rate: {learning_rate}, Average_val_loss: {average_val_loss}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "best_params = max(results, key=lambda x: x['val_accuracy'])\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Init Batch size: 100, Epochs: 3, Learning rate: 0.001\n",
      "Epoch 1/3\n",
      "Step 1/200, Loss: 0.6899\n",
      "Step 2/200, Loss: 0.6852\n",
      "Step 3/200, Loss: 0.6950\n",
      "Step 4/200, Loss: 0.6883\n",
      "Step 5/200, Loss: 0.6932\n",
      "Step 6/200, Loss: 0.6880\n",
      "Step 7/200, Loss: 0.6894\n",
      "Step 8/200, Loss: 0.6869\n",
      "Step 9/200, Loss: 0.6920\n",
      "Step 10/200, Loss: 0.6812\n",
      "Step 11/200, Loss: 0.6868\n",
      "Step 12/200, Loss: 0.6947\n",
      "Step 13/200, Loss: 0.6918\n",
      "Step 14/200, Loss: 0.6824\n",
      "Step 15/200, Loss: 0.6869\n",
      "Step 16/200, Loss: 0.6791\n",
      "Step 17/200, Loss: 0.6849\n",
      "Step 18/200, Loss: 0.6900\n",
      "Step 19/200, Loss: 0.6855\n",
      "Step 20/200, Loss: 0.6945\n",
      "Step 21/200, Loss: 0.6860\n",
      "Step 22/200, Loss: 0.7020\n",
      "Step 23/200, Loss: 0.6865\n",
      "Step 24/200, Loss: 0.7088\n",
      "Step 25/200, Loss: 0.6876\n",
      "Step 26/200, Loss: 0.6899\n",
      "Step 27/200, Loss: 0.6830\n",
      "Step 28/200, Loss: 0.7137\n",
      "Step 29/200, Loss: 0.6763\n",
      "Step 30/200, Loss: 0.7047\n",
      "Step 31/200, Loss: 0.6834\n",
      "Step 32/200, Loss: 0.6967\n",
      "Step 33/200, Loss: 0.6888\n",
      "Step 34/200, Loss: 0.6827\n",
      "Step 35/200, Loss: 0.6981\n",
      "Step 36/200, Loss: 0.6995\n",
      "Step 37/200, Loss: 0.6929\n",
      "Step 38/200, Loss: 0.6865\n",
      "Step 39/200, Loss: 0.6844\n",
      "Step 40/200, Loss: 0.6924\n",
      "Step 41/200, Loss: 0.6926\n",
      "Step 42/200, Loss: 0.7046\n",
      "Step 43/200, Loss: 0.7125\n",
      "Step 44/200, Loss: 0.6770\n",
      "Step 45/200, Loss: 0.6867\n",
      "Step 46/200, Loss: 0.7063\n",
      "Step 47/200, Loss: 0.7024\n",
      "Step 48/200, Loss: 0.6794\n",
      "Step 49/200, Loss: 0.6991\n",
      "Step 50/200, Loss: 0.7113\n",
      "Step 51/200, Loss: 0.6850\n",
      "Step 52/200, Loss: 0.6854\n",
      "Step 53/200, Loss: 0.7127\n",
      "Step 54/200, Loss: 0.6904\n",
      "Step 55/200, Loss: 0.6914\n",
      "Step 56/200, Loss: 0.6928\n",
      "Step 57/200, Loss: 0.6995\n",
      "Step 58/200, Loss: 0.6910\n",
      "Step 59/200, Loss: 0.6840\n",
      "Step 60/200, Loss: 0.7069\n",
      "Step 61/200, Loss: 0.6927\n",
      "Step 62/200, Loss: 0.6916\n",
      "Step 63/200, Loss: 0.6965\n",
      "Step 64/200, Loss: 0.6976\n",
      "Step 65/200, Loss: 0.6919\n",
      "Step 66/200, Loss: 0.6925\n",
      "Step 67/200, Loss: 0.6917\n",
      "Step 68/200, Loss: 0.6923\n",
      "Step 69/200, Loss: 0.6924\n",
      "Step 70/200, Loss: 0.6928\n",
      "Step 71/200, Loss: 0.6908\n",
      "Step 72/200, Loss: 0.6899\n",
      "Step 73/200, Loss: 0.6928\n",
      "Step 74/200, Loss: 0.6917\n",
      "Step 75/200, Loss: 0.6876\n",
      "Step 76/200, Loss: 0.6904\n",
      "Step 77/200, Loss: 0.6931\n",
      "Step 78/200, Loss: 0.6888\n",
      "Step 79/200, Loss: 0.6938\n",
      "Step 80/200, Loss: 0.6922\n",
      "Step 81/200, Loss: 0.6938\n",
      "Step 82/200, Loss: 0.6899\n",
      "Step 83/200, Loss: 0.6891\n",
      "Step 84/200, Loss: 0.6921\n",
      "Step 85/200, Loss: 0.6884\n",
      "Step 86/200, Loss: 0.6915\n",
      "Step 87/200, Loss: 0.6934\n",
      "Step 88/200, Loss: 0.6882\n",
      "Step 89/200, Loss: 0.6909\n",
      "Step 90/200, Loss: 0.6930\n",
      "Step 91/200, Loss: 0.6900\n",
      "Step 92/200, Loss: 0.6905\n",
      "Step 93/200, Loss: 0.6981\n",
      "Step 94/200, Loss: 0.6876\n",
      "Step 95/200, Loss: 0.6993\n",
      "Step 96/200, Loss: 0.6850\n",
      "Step 97/200, Loss: 0.6932\n",
      "Step 98/200, Loss: 0.6866\n",
      "Step 99/200, Loss: 0.6941\n",
      "Step 100/200, Loss: 0.6872\n",
      "Step 101/200, Loss: 0.6884\n",
      "Step 102/200, Loss: 0.6987\n",
      "Step 103/200, Loss: 0.6850\n",
      "Step 104/200, Loss: 0.6947\n",
      "Step 105/200, Loss: 0.6852\n",
      "Step 106/200, Loss: 0.6953\n",
      "Step 107/200, Loss: 0.6861\n",
      "Step 108/200, Loss: 0.6894\n",
      "Step 109/200, Loss: 0.6853\n",
      "Step 110/200, Loss: 0.6958\n",
      "Step 111/200, Loss: 0.6869\n",
      "Step 112/200, Loss: 0.6936\n",
      "Step 113/200, Loss: 0.6941\n",
      "Step 114/200, Loss: 0.6838\n",
      "Step 115/200, Loss: 0.6829\n",
      "Step 116/200, Loss: 0.6969\n",
      "Step 117/200, Loss: 0.6834\n",
      "Step 118/200, Loss: 0.6871\n",
      "Step 119/200, Loss: 0.6877\n",
      "Step 120/200, Loss: 0.7042\n",
      "Step 121/200, Loss: 0.7002\n",
      "Step 122/200, Loss: 0.6888\n",
      "Step 123/200, Loss: 0.6877\n",
      "Step 124/200, Loss: 0.6909\n",
      "Step 125/200, Loss: 0.6960\n",
      "Step 126/200, Loss: 0.6884\n",
      "Step 127/200, Loss: 0.6907\n",
      "Step 128/200, Loss: 0.6872\n",
      "Step 129/200, Loss: 0.7034\n",
      "Step 130/200, Loss: 0.6886\n",
      "Step 131/200, Loss: 0.6882\n",
      "Step 132/200, Loss: 0.6980\n",
      "Step 133/200, Loss: 0.6883\n",
      "Step 134/200, Loss: 0.6929\n",
      "Step 135/200, Loss: 0.6911\n",
      "Step 136/200, Loss: 0.6878\n",
      "Step 137/200, Loss: 0.6950\n",
      "Step 138/200, Loss: 0.6880\n",
      "Step 139/200, Loss: 0.6877\n",
      "Step 140/200, Loss: 0.6988\n",
      "Step 141/200, Loss: 0.6873\n",
      "Step 142/200, Loss: 0.6937\n",
      "Step 143/200, Loss: 0.6961\n",
      "Step 144/200, Loss: 0.6882\n",
      "Step 145/200, Loss: 0.6879\n",
      "Step 146/200, Loss: 0.6823\n",
      "Step 147/200, Loss: 0.6919\n",
      "Step 148/200, Loss: 0.6973\n",
      "Step 149/200, Loss: 0.6963\n",
      "Step 150/200, Loss: 0.6880\n",
      "Step 151/200, Loss: 0.6893\n",
      "Step 152/200, Loss: 0.6852\n",
      "Step 153/200, Loss: 0.6895\n",
      "Step 154/200, Loss: 0.6937\n",
      "Step 155/200, Loss: 0.6904\n",
      "Step 156/200, Loss: 0.6846\n",
      "Step 157/200, Loss: 0.6898\n",
      "Step 158/200, Loss: 0.6893\n",
      "Step 159/200, Loss: 0.6946\n",
      "Step 160/200, Loss: 0.6962\n",
      "Step 161/200, Loss: 0.6903\n",
      "Step 162/200, Loss: 0.6875\n",
      "Step 163/200, Loss: 0.6918\n",
      "Step 164/200, Loss: 0.6928\n",
      "Step 165/200, Loss: 0.6921\n",
      "Step 166/200, Loss: 0.6941\n",
      "Step 167/200, Loss: 0.6881\n",
      "Step 168/200, Loss: 0.6926\n",
      "Step 169/200, Loss: 0.6897\n",
      "Step 170/200, Loss: 0.6905\n",
      "Step 171/200, Loss: 0.6876\n",
      "Step 172/200, Loss: 0.6905\n",
      "Step 173/200, Loss: 0.6901\n",
      "Step 174/200, Loss: 0.6874\n",
      "Step 175/200, Loss: 0.6871\n",
      "Step 176/200, Loss: 0.6937\n",
      "Step 177/200, Loss: 0.6926\n",
      "Step 178/200, Loss: 0.6923\n",
      "Step 179/200, Loss: 0.6976\n",
      "Step 180/200, Loss: 0.6889\n",
      "Step 181/200, Loss: 0.6918\n",
      "Step 182/200, Loss: 0.6897\n",
      "Step 183/200, Loss: 0.6962\n",
      "Step 184/200, Loss: 0.6938\n",
      "Step 185/200, Loss: 0.6861\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Elman(nn.Module):\n",
    "    def __init__(self, insize=300, outsize=300, hsize=300):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(insize * 2, hsize)\n",
    "        self.lin2 = nn.Linear(hsize, outsize)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        b, t, e = x.size()\n",
    "\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(b, e, dtype=torch.float)\n",
    "\n",
    "        outs = []\n",
    "        for i in range(t):\n",
    "            inp = torch.cat([x[:, i, :], hidden], dim=1)\n",
    "            hidden = self.relu(self.lin1(inp))\n",
    "            out = self.lin2(hidden)\n",
    "            outs.append(out[:, None, :])\n",
    "        return torch.cat(outs, dim=1), hidden\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNN, self).__init__()\n",
    "\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.elman = Elman(embedding_dim, hidden_dim)\n",
    "        self.linear_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_text):\n",
    "        embedded = self.embedding(input_text)\n",
    "        elman_out, _ = self.elman(embedded)\n",
    "        pooled_output, _ = torch.max(elman_out, dim=1)\n",
    "        output = self.linear_out(pooled_output)\n",
    "        return output\n",
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "vocab_size = len(i2w)\n",
    "embedding_dim = 300\n",
    "hidden_size = 300\n",
    "output_dim = 2\n",
    "param_grid = {\n",
    "    'batch_size': [100, 300, 500],\n",
    "    'epochs': [3, 5, 7],\n",
    "    'learning_rate': [0.001, 0.005, 0.01]\n",
    "}\n",
    "\n",
    "# Create parameter grid\n",
    "grid = ParameterGrid(param_grid)\n",
    "results = []\n",
    "\n",
    "for params in grid:\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    learning_rate = params['learning_rate']\n",
    "    model = RNN(vocab_size, embedding_dim, hidden_size, output_dim)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    print(f\"Init Batch size: {batch_size}, Epochs: {epochs}, Learning rate: {learning_rate}\")\n",
    "    # Assuming x_train, y_train, x_val, y_val are already on the same device (GPU)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        x_train_gen = (x_train[i - batch_size:i] for i in range(batch_size, len(x_train), batch_size - 1))\n",
    "        y_train_gen = (y_train[i - batch_size:i] for i in range(batch_size, len(y_train), batch_size - 1))\n",
    "\n",
    "        for step in range(int(len(x_train) / batch_size)):\n",
    "            x_train_batch, y_train_batch = (\n",
    "                batch_padding(next(x_train_gen)),\n",
    "                torch.tensor(next(y_train_gen), dtype=torch.long),\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(x_train_batch)\n",
    "\n",
    "            loss = criterion(outputs.squeeze(), y_train_batch)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            print(f\"Step {step + 1}/{int(len(x_train) / batch_size)}, Loss: {loss.item():.4f}\")\n",
    "        average_loss = total_loss / (len(x_train) / batch_size)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {average_loss:.4f}\")\n",
    "\n",
    "        # Validation Loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Reset the generators\n",
    "        x_val_gen = (x_val[i - batch_size:i] for i in range(batch_size, len(x_val), batch_size - 1))\n",
    "        y_val_gen = (y_val[i - batch_size:i] for i in range(batch_size, len(y_val), batch_size - 1))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_step in range(int(len(x_val) / batch_size)):\n",
    "                x_val_batch, y_val_batch = (\n",
    "                    batch_padding(next(x_val_gen)),\n",
    "                    torch.tensor(next(y_val_gen), dtype=torch.long),\n",
    "                )\n",
    "\n",
    "                outputs = model(x_val_batch)\n",
    "                loss = criterion(outputs.squeeze(), y_val_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predictions = torch.argmax(torch.softmax(outputs, 1), dim=1)\n",
    "                correct_predictions += (predictions == y_val_batch).sum().item()\n",
    "                total_samples += y_val_batch.size(0)\n",
    "\n",
    "        average_val_loss = val_loss / (len(x_val) / batch_size)\n",
    "        val_accuracy = correct_predictions / total_samples\n",
    "        #print(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        results.append({\n",
    "        'batch_size': batch_size,\n",
    "        'epochs': epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'average_val_loss': average_val_loss,\n",
    "        'val_accuracy': val_accuracy\n",
    "    })\n",
    "    print(f\"Batch size: {batch_size}, Epochs: {epochs}, Learning rate: {learning_rate}, Average_val_loss: {average_val_loss}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "best_params = max(results, key=lambda x: x['val_accuracy'])\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(600, device='cuda:0')"
      ]
     },
     "execution_count": 185,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_dim = 300\n",
    "# embedding_dim to GPU\n",
    "embedding_dim = torch.tensor(embedding_dim, device=device)\n",
    "embedding_dim * 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
