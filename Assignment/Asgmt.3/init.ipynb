{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wget, os, gzip, pickle, random, re, sys\n",
    "\n",
    "IMDB_URL = 'http://dlvu.github.io/data/imdb.{}.pkl.gz'\n",
    "IMDB_FILE = 'imdb.{}.pkl.gz'\n",
    "\n",
    "PAD, START, END, UNK = '.pad', '.start', '.end', '.unk'\n",
    "\n",
    "def load_imdb(final=False, val=5000, seed=0, voc=None, char=False):\n",
    "\n",
    "    cst = 'char' if char else 'word'\n",
    "\n",
    "    imdb_url = IMDB_URL.format(cst)\n",
    "    imdb_file = IMDB_FILE.format(cst)\n",
    "\n",
    "    if not os.path.exists(imdb_file):\n",
    "        wget.download(imdb_url)\n",
    "\n",
    "    with gzip.open(imdb_file) as file:\n",
    "        sequences, labels, i2w, w2i = pickle.load(file)\n",
    "\n",
    "    if voc is not None and voc < len(i2w):\n",
    "        nw_sequences = {}\n",
    "\n",
    "        i2w = i2w[:voc]\n",
    "        w2i = {w: i for i, w in enumerate(i2w)}\n",
    "\n",
    "        mx, unk = voc, w2i['.unk']\n",
    "        for key, seqs in sequences.items():\n",
    "            nw_sequences[key] = []\n",
    "            for seq in seqs:\n",
    "                seq = [s if s < mx else unk for s in seq]\n",
    "                nw_sequences[key].append(seq)\n",
    "\n",
    "        sequences = nw_sequences\n",
    "\n",
    "    if final:\n",
    "        return (sequences['train'], labels['train']), (sequences['test'], labels['test']), (i2w, w2i), 2\n",
    "\n",
    "    # Make a validation split\n",
    "    random.seed(seed)\n",
    "\n",
    "    x_train, y_train = [], []\n",
    "    x_val, y_val = [], []\n",
    "\n",
    "    val_ind = set( random.sample(range(len(sequences['train'])), k=val) )\n",
    "    for i, (s, l) in enumerate(zip(sequences['train'], labels['train'])):\n",
    "        if i in val_ind:\n",
    "            x_val.append(s)\n",
    "            y_val.append(l)\n",
    "        else:\n",
    "            x_train.append(s)\n",
    "            y_train.append(l)\n",
    "\n",
    "    return (x_train, y_train), \\\n",
    "           (x_val, y_val), \\\n",
    "           (i2w, w2i), 2\n",
    "\n",
    "\n",
    "def gen_sentence(sent, g):\n",
    "\n",
    "    symb = '_[a-z]*'\n",
    "\n",
    "    while True:\n",
    "\n",
    "        match = re.search(symb, sent)\n",
    "        if match is None:\n",
    "            return sent\n",
    "\n",
    "        s = match.span()\n",
    "        sent = sent[:s[0]] + random.choice(g[sent[s[0]:s[1]]]) + sent[s[1]:]\n",
    "\n",
    "def gen_dyck(p):\n",
    "    open = 1\n",
    "    sent = '('\n",
    "    while open > 0:\n",
    "        if random.random() < p:\n",
    "            sent += '('\n",
    "            open += 1\n",
    "        else:\n",
    "            sent += ')'\n",
    "            open -= 1\n",
    "\n",
    "    return sent\n",
    "\n",
    "def gen_ndfa(p):\n",
    "\n",
    "    word = random.choice(['abc!', 'uvw!', 'klm!'])\n",
    "\n",
    "    s = ''\n",
    "    while True:\n",
    "        if random.random() < p:\n",
    "            return 's' + s + 's'\n",
    "        else:\n",
    "            s+= word\n",
    "\n",
    "def load_brackets(n=50_000, seed=0):\n",
    "    return load_toy(n, char=True, seed=seed, name='dyck')\n",
    "\n",
    "def load_ndfa(n=50_000, seed=0):\n",
    "    return load_toy(n, char=True, seed=seed, name='ndfa')\n",
    "\n",
    "def load_toy(n=50_000, char=True, seed=0, name='lang'):\n",
    "\n",
    "    random.seed(0)\n",
    "\n",
    "    if name == 'lang':\n",
    "        sent = '_s'\n",
    "\n",
    "        toy = {\n",
    "            '_s': ['_s _adv', '_np _vp', '_np _vp _prep _np', '_np _vp ( _prep _np )', '_np _vp _con _s' , '_np _vp ( _con _s )'],\n",
    "            '_adv': ['briefly', 'quickly', 'impatiently'],\n",
    "            '_np': ['a _noun', 'the _noun', 'a _adj _noun', 'the _adj _noun'],\n",
    "            '_prep': ['on', 'with', 'to'],\n",
    "            '_con' : ['while', 'but'],\n",
    "            '_noun': ['mouse', 'bunny', 'cat', 'dog', 'man', 'woman', 'person'],\n",
    "            '_vp': ['walked', 'walks', 'ran', 'runs', 'goes', 'went'],\n",
    "            '_adj': ['short', 'quick', 'busy', 'nice', 'gorgeous']\n",
    "        }\n",
    "\n",
    "        sentences = [ gen_sentence(sent, toy) for _ in range(n)]\n",
    "        sentences.sort(key=lambda s : len(s))\n",
    "\n",
    "    elif name == 'dyck':\n",
    "\n",
    "        sentences = [gen_dyck(7./16.) for _ in range(n)]\n",
    "        sentences.sort(key=lambda s: len(s))\n",
    "\n",
    "    elif name == 'ndfa':\n",
    "\n",
    "        sentences = [gen_ndfa(1./4.) for _ in range(n)]\n",
    "        sentences.sort(key=lambda s: len(s))\n",
    "\n",
    "    else:\n",
    "        raise Exception(name)\n",
    "\n",
    "    tokens = set()\n",
    "    for s in sentences:\n",
    "\n",
    "        if char:\n",
    "            for c in s:\n",
    "                tokens.add(c)\n",
    "        else:\n",
    "            for w in s.split():\n",
    "                tokens.add(w)\n",
    "\n",
    "    i2t = [PAD, START, END, UNK] + list(tokens)\n",
    "    t2i = {t:i for i, t in enumerate(i2t)}\n",
    "\n",
    "    sequences = []\n",
    "    for s in sentences:\n",
    "        if char:\n",
    "            tok = list(s)\n",
    "        else:\n",
    "            tok = s.split()\n",
    "        sequences.append([t2i[t] for t in tok])\n",
    "\n",
    "    return sequences, (i2t, t2i)\n",
    "(x_train, y_train), (x_val, y_val), (i2w, w2i), numcls = load_imdb(final=False)\n",
    "# x_train A python list of lists of integers. Each integer represents a word. Sorted from short to long.\n",
    "# i2w A list of strings mapping the integers in the sequences to their original words.\n",
    "# w2i A dictionary mapping the words to their indices. w2i['film'] returns the index for the word \"film\".\n",
    "# 0 -> positive, 1 -> negative\n",
    "# print(x_train[141][:5])\n",
    "# print([i2w[w] for w in x_train[141]])\n",
    "# print([w2i[i] for i in [i2w[w] for w in x_train[141]]][:5])\n",
    "# print(y_train[141])\n",
    "# print(numcls)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def batch_padding(batch):\n",
    "    padded_batch = []; max_len = max(len(x) for x in batch)+2\n",
    "    for seq in batch:\n",
    "        seq = [w2i['.start']] + seq + [w2i['.end']]\n",
    "        if len(seq) < max_len:\n",
    "            seq += [w2i['.pad']] * (max_len - len(seq))\n",
    "        padded_batch.append(seq)\n",
    "    return torch.tensor(padded_batch, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.optim as optim\n",
    "\n",
    "class SimpleRNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(SimpleRNN, self).__init__()\n",
    "\n",
    "        # Embedding layer\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "\n",
    "        # Linear layer with ReLU activation\n",
    "        self.linear_relu = nn.Linear(embedding_dim, hidden_dim)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        # Linear layer for binary classification\n",
    "        self.linear_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_text):\n",
    "        # Embedding layer\n",
    "        embedded = self.embedding(input_text)\n",
    "\n",
    "        # Linear layer with ReLU activation\n",
    "        linear_output = self.relu(self.linear_relu(embedded))\n",
    "\n",
    "        # Global max pooling layer\n",
    "        pooled_output, _ = torch.max(linear_output, dim=1)\n",
    "\n",
    "        # Linear layer for binary classification\n",
    "        output = self.linear_out(pooled_output)\n",
    "\n",
    "        return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch size: 50, Epochs: 3, Learning rate: 0.001, Average_val_loss: 0.6319688534736634, Validation Accuracy: 0.6866\n",
      "Batch size: 50, Epochs: 3, Learning rate: 0.005, Average_val_loss: 0.465954367518425, Validation Accuracy: 0.7746\n",
      "Batch size: 50, Epochs: 3, Learning rate: 0.01, Average_val_loss: 0.736927616596222, Validation Accuracy: 0.6784\n",
      "Batch size: 50, Epochs: 5, Learning rate: 0.001, Average_val_loss: 0.6231666350364685, Validation Accuracy: 0.6940\n",
      "Batch size: 50, Epochs: 5, Learning rate: 0.005, Average_val_loss: 0.39970849856734275, Validation Accuracy: 0.8136\n",
      "Batch size: 50, Epochs: 5, Learning rate: 0.01, Average_val_loss: 0.493350368142128, Validation Accuracy: 0.7824\n",
      "Batch size: 50, Epochs: 7, Learning rate: 0.001, Average_val_loss: 0.5726725146174431, Validation Accuracy: 0.7190\n",
      "Batch size: 50, Epochs: 7, Learning rate: 0.005, Average_val_loss: 0.41256222277879717, Validation Accuracy: 0.8058\n",
      "Batch size: 50, Epochs: 7, Learning rate: 0.01, Average_val_loss: 0.3462300319969654, Validation Accuracy: 0.8506\n",
      "Batch size: 100, Epochs: 3, Learning rate: 0.001, Average_val_loss: 0.6534315574169159, Validation Accuracy: 0.6440\n",
      "Batch size: 100, Epochs: 3, Learning rate: 0.005, Average_val_loss: 0.5671027708053589, Validation Accuracy: 0.7150\n",
      "Batch size: 100, Epochs: 3, Learning rate: 0.01, Average_val_loss: 0.9565401041507721, Validation Accuracy: 0.5860\n",
      "Batch size: 100, Epochs: 5, Learning rate: 0.001, Average_val_loss: 0.6471119832992553, Validation Accuracy: 0.6500\n",
      "Batch size: 100, Epochs: 5, Learning rate: 0.005, Average_val_loss: 0.46200624585151673, Validation Accuracy: 0.7872\n",
      "Batch size: 100, Epochs: 5, Learning rate: 0.01, Average_val_loss: 0.4562406557798386, Validation Accuracy: 0.7844\n",
      "Batch size: 100, Epochs: 7, Learning rate: 0.001, Average_val_loss: 0.5981363475322723, Validation Accuracy: 0.7278\n",
      "Batch size: 100, Epochs: 7, Learning rate: 0.005, Average_val_loss: 0.4329436945915222, Validation Accuracy: 0.8000\n",
      "Batch size: 100, Epochs: 7, Learning rate: 0.01, Average_val_loss: 0.3513597047328949, Validation Accuracy: 0.8442\n",
      "Batch size: 200, Epochs: 3, Learning rate: 0.001, Average_val_loss: 0.6818029022216797, Validation Accuracy: 0.5584\n",
      "Batch size: 200, Epochs: 3, Learning rate: 0.005, Average_val_loss: 0.6603087186813354, Validation Accuracy: 0.5328\n",
      "Batch size: 200, Epochs: 3, Learning rate: 0.01, Average_val_loss: 1.6470994758605957, Validation Accuracy: 0.5008\n",
      "Batch size: 200, Epochs: 5, Learning rate: 0.001, Average_val_loss: 0.6728029561042785, Validation Accuracy: 0.5732\n",
      "Batch size: 200, Epochs: 5, Learning rate: 0.005, Average_val_loss: 0.5555780386924744, Validation Accuracy: 0.7242\n",
      "Batch size: 200, Epochs: 5, Learning rate: 0.01, Average_val_loss: 0.792051203250885, Validation Accuracy: 0.5904\n",
      "Batch size: 200, Epochs: 7, Learning rate: 0.001, Average_val_loss: 0.6606175684928894, Validation Accuracy: 0.6330\n",
      "Batch size: 200, Epochs: 7, Learning rate: 0.005, Average_val_loss: 0.5176939785480499, Validation Accuracy: 0.7546\n",
      "Batch size: 200, Epochs: 7, Learning rate: 0.01, Average_val_loss: 0.6329993963241577, Validation Accuracy: 0.6786\n",
      "Best parameters: {'batch_size': 50, 'epochs': 7, 'learning_rate': 0.01, 'average_val_loss': 0.3462300319969654, 'val_accuracy': 0.8506}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Apply GPU\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "torch.manual_seed(0)\n",
    "vocab_size = len(i2w)\n",
    "embedding_dim = 300\n",
    "hidden_size = 300\n",
    "output_dim = 2\n",
    "param_grid = {\n",
    "    'batch_size': [50, 100, 200],\n",
    "    'epochs': [3, 5, 7],\n",
    "    'learning_rate': [0.001, 0.005, 0.01]\n",
    "}\n",
    "\n",
    "# Create parameter grid\n",
    "grid = ParameterGrid(param_grid)\n",
    "results = []\n",
    "\n",
    "for params in grid:\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    learning_rate = params['learning_rate']\n",
    "# Instantiate the model and move it to the device\n",
    "    model = SimpleRNN(vocab_size, embedding_dim, hidden_size, output_dim).to(device)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss() # combines nn.LogSoftmax() and nn.NLLLoss() in one.\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        \n",
    "        # create batch generators in steps of batch_size-1\n",
    "        x_train_gen = (x_train[i-batch_size:i] for i in range(batch_size, len(x_train), batch_size-1))\n",
    "        y_train_gen = (y_train[i-batch_size:i] for i in range(batch_size, len(y_train), batch_size-1))\n",
    "        \n",
    "        x_val_gen = (x_val[i-batch_size:i] for i in range(batch_size, len(x_val), batch_size-1))\n",
    "        y_val_gen = (y_val[i-batch_size:i] for i in range(batch_size, len(y_val), batch_size-1))\n",
    "        \n",
    "        # Loop over batches\n",
    "        for step in range(int(len(x_train)/batch_size)):\n",
    "            # Extract batch and perform padding\n",
    "            x_train_batch, y_train_batch = (batch_padding(next(x_train_gen)),\n",
    "                                            torch.tensor(next(y_train_gen), dtype=torch.long))\n",
    "            \n",
    "            # Move the data to the device\n",
    "            x_train_batch = x_train_batch.to(device)\n",
    "            y_train_batch = y_train_batch.to(device)\n",
    "            \n",
    "            # Zero the gradients\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(x_train_batch)\n",
    "\n",
    "            # Calculate the loss\n",
    "            loss = criterion(outputs.squeeze(), y_train_batch) # squeeze() removes the extra dimension\n",
    "\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "\n",
    "            # Update weights\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "\n",
    "        average_loss = total_loss / (len(x_train) / batch_size)\n",
    "        #print(f\"Epoch {epoch + 1}/{epochs}, Loss: {average_loss:.4f}\")\n",
    "        \n",
    "        # Model Validation\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Turn of gradient for faster computation\n",
    "        with torch.no_grad():\n",
    "            for val_step in range(int(len(x_val)/batch_size)):\n",
    "                # Extract validation batches\n",
    "                x_val_batch, y_val_batch = (batch_padding(next(x_val_gen)),\n",
    "                                            torch.tensor(next(y_val_gen), dtype=torch.long))\n",
    "\n",
    "                # Move the data to the device\n",
    "                x_val_batch = x_val_batch.to(device)\n",
    "                y_val_batch = y_val_batch.to(device)\n",
    "\n",
    "                # Forward pass and compute loss\n",
    "                outputs = model(x_val_batch)\n",
    "                loss = criterion(outputs.squeeze(), y_val_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                # Compare predictions with ground-truth\n",
    "                predictions = torch.argmax(torch.softmax(outputs,1),dim=1)\n",
    "                correct_predictions += (predictions == y_val_batch).sum().item()\n",
    "                total_samples += y_val_batch.size(0)\n",
    "\n",
    "        average_val_loss = val_loss / (len(x_val) / batch_size)\n",
    "        val_accuracy = correct_predictions / total_samples\n",
    "        #print(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "    results.append({\n",
    "        'batch_size': batch_size,\n",
    "        'epochs': epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'average_val_loss': average_val_loss,\n",
    "        'val_accuracy': val_accuracy\n",
    "    })\n",
    "    #print(f\"Batch size: {batch_size}, Epochs: {epochs}, Learning rate: {learning_rate}, Average_val_loss: {average_val_loss}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "best_params = max(results, key=lambda x: x['val_accuracy'])\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Q4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "class Elman(nn.Module):\n",
    "    def __init__(self, insize=300, outsize=300, hsize=300):\n",
    "        super().__init__()\n",
    "        self.lin1 = nn.Linear(insize * 2, hsize)\n",
    "        self.lin2 = nn.Linear(hsize, outsize)\n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "    def forward(self, x, hidden=None):\n",
    "        b, t, e = x.size()\n",
    "\n",
    "        if hidden is None:\n",
    "            hidden = torch.zeros(b, e, dtype=torch.float)\n",
    "        outs = []\n",
    "        \n",
    "        for i in range(t):\n",
    "            inp = torch.cat([x[:, i, :], hidden], dim=1)\n",
    "            hidden = self.relu(self.lin1(inp))\n",
    "            out = self.lin2(hidden)\n",
    "            outs.append(out[:, None, :])\n",
    "        return torch.cat(outs, dim=1), hidden\n",
    "\n",
    "class RNN(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.elman = Elman(embedding_dim, hidden_dim)\n",
    "        self.linear_out = nn.Linear(hidden_dim, output_dim)\n",
    "\n",
    "    def forward(self, input_text):\n",
    "        embedded = self.embedding(input_text)\n",
    "        elman_out, _ = self.elman(embedded)\n",
    "        pooled_output, _ = torch.max(elman_out, dim=1)\n",
    "        output = self.linear_out(pooled_output)\n",
    "        return output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "torch.manual_seed(0)\n",
    "vocab_size = len(i2w)\n",
    "embedding_dim = 300\n",
    "hidden_size = 300\n",
    "output_dim = 2\n",
    "param_grid = {\n",
    "    'batch_size': [100, 300, 500],\n",
    "    'epochs': [3, 5, 7],\n",
    "    'learning_rate': [0.001, 0.005, 0.01]\n",
    "}\n",
    "\n",
    "# Create parameter grid\n",
    "grid = ParameterGrid(param_grid)\n",
    "results = []\n",
    "\n",
    "for params in grid:\n",
    "    batch_size = params['batch_size']\n",
    "    epochs = params['epochs']\n",
    "    learning_rate = params['learning_rate']\n",
    "    model = RNN(vocab_size, embedding_dim, hidden_size, output_dim)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "    print(f\"Init Batch size: {batch_size}, Epochs: {epochs}, Learning rate: {learning_rate}\")\n",
    "    # Assuming x_train, y_train, x_val, y_val are already on the same device (GPU)\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        total_loss = 0.0\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}\")\n",
    "        x_train_gen = (x_train[i - batch_size:i] for i in range(batch_size, len(x_train), batch_size - 1))\n",
    "        y_train_gen = (y_train[i - batch_size:i] for i in range(batch_size, len(y_train), batch_size - 1))\n",
    "\n",
    "        for step in range(int(len(x_train) / batch_size)):\n",
    "            x_train_batch, y_train_batch = (\n",
    "                batch_padding(next(x_train_gen)),\n",
    "                torch.tensor(next(y_train_gen), dtype=torch.long),\n",
    "            )\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            outputs = model(x_train_batch)\n",
    "\n",
    "            loss = criterion(outputs.squeeze(), y_train_batch)\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            optimizer.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            print(f\"Step {step + 1}/{int(len(x_train) / batch_size)}, Loss: {loss.item():.4f}\")\n",
    "        average_loss = total_loss / (len(x_train) / batch_size)\n",
    "        print(f\"Epoch {epoch + 1}/{epochs}, Loss: {average_loss:.4f}\")\n",
    "\n",
    "        # Validation Loop\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        correct_predictions = 0\n",
    "        total_samples = 0\n",
    "\n",
    "        # Reset the generators\n",
    "        x_val_gen = (x_val[i - batch_size:i] for i in range(batch_size, len(x_val), batch_size - 1))\n",
    "        y_val_gen = (y_val[i - batch_size:i] for i in range(batch_size, len(y_val), batch_size - 1))\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for val_step in range(int(len(x_val) / batch_size)):\n",
    "                x_val_batch, y_val_batch = (\n",
    "                    batch_padding(next(x_val_gen)),\n",
    "                    torch.tensor(next(y_val_gen), dtype=torch.long),\n",
    "                )\n",
    "\n",
    "                outputs = model(x_val_batch)\n",
    "                loss = criterion(outputs.squeeze(), y_val_batch)\n",
    "                val_loss += loss.item()\n",
    "\n",
    "                predictions = torch.argmax(torch.softmax(outputs, 1), dim=1)\n",
    "                correct_predictions += (predictions == y_val_batch).sum().item()\n",
    "                total_samples += y_val_batch.size(0)\n",
    "\n",
    "        average_val_loss = val_loss / (len(x_val) / batch_size)\n",
    "        val_accuracy = correct_predictions / total_samples\n",
    "        #print(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "        results.append({\n",
    "        'batch_size': batch_size,\n",
    "        'epochs': epochs,\n",
    "        'learning_rate': learning_rate,\n",
    "        'average_val_loss': average_val_loss,\n",
    "        'val_accuracy': val_accuracy\n",
    "    })\n",
    "    print(f\"Batch size: {batch_size}, Epochs: {epochs}, Learning rate: {learning_rate}, Average_val_loss: {average_val_loss}, Validation Accuracy: {val_accuracy:.4f}\")\n",
    "best_params = max(results, key=lambda x: x['val_accuracy'])\n",
    "print(f\"Best parameters: {best_params}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch step: 1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[217], line 41\u001b[0m\n\u001b[1;32m     38\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     40\u001b[0m  \u001b[38;5;66;03m# Forward pass\u001b[39;00m\n\u001b[0;32m---> 41\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx_train_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;66;03m# Calculate the loss\u001b[39;00m\n\u001b[1;32m     44\u001b[0m loss \u001b[38;5;241m=\u001b[39m criterion(outputs\u001b[38;5;241m.\u001b[39msqueeze(), y_train_batch)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[210], line 35\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, input_text)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, input_text):\n\u001b[1;32m     34\u001b[0m     embedded \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedding(input_text)\n\u001b[0;32m---> 35\u001b[0m     elman_out, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43melman\u001b[49m\u001b[43m(\u001b[49m\u001b[43membedded\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     pooled_output, _ \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmax(elman_out, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m     37\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlinear_out(pooled_output)\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1518\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1516\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1517\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1518\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.10/site-packages/torch/nn/modules/module.py:1527\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1522\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1523\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1524\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1525\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1526\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1527\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1529\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1530\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[210], line 20\u001b[0m, in \u001b[0;36mElman.forward\u001b[0;34m(self, x, hidden)\u001b[0m\n\u001b[1;32m     17\u001b[0m outs \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(t):\n\u001b[0;32m---> 20\u001b[0m     inp \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mhidden\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     21\u001b[0m     hidden \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrelu(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin1(inp))\n\u001b[1;32m     22\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlin2(hidden)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu! (when checking argument for argument tensors in method wrapper_CUDA_cat)"
     ]
    }
   ],
   "source": [
    "torch.manual_seed(0)\n",
    "vocab_size = len(i2w)\n",
    "embedding_dim = 300\n",
    "hidden_size = 300\n",
    "output_dim = 2\n",
    "batch_size = 100\n",
    "epochs = 1\n",
    "learning_rate = 0.005\n",
    "\n",
    "# Check if GPU is available\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Instantiate the model and move it to the device\n",
    "model = RNN(vocab_size, embedding_dim, hidden_size, output_dim).to(device)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    \n",
    "    # create batch generators in steps of batch_size-1\n",
    "    x_train_gen = (x_train[i-batch_size:i] for i in range(batch_size, len(x_train), batch_size-1))\n",
    "    y_train_gen = (y_train[i-batch_size:i] for i in range(batch_size, len(y_train), batch_size-1))\n",
    "    \n",
    "    x_val_gen = (x_val[i-batch_size:i] for i in range(batch_size, len(x_val), batch_size-1))\n",
    "    y_val_gen = (y_val[i-batch_size:i] for i in range(batch_size, len(y_val), batch_size-1))\n",
    "    \n",
    "    # Loop over batches\n",
    "    for step in range(int(len(x_train)/batch_size)):\n",
    "        print(f\"Batch step: {step+1}\")\n",
    "        # Extract batch and perform padding\n",
    "        x_train_batch, y_train_batch = (batch_padding(next(x_train_gen)).to(device),\n",
    "                                        torch.tensor(next(y_train_gen), dtype=torch.long).to(device))\n",
    "        \n",
    "        # Zero the gradients\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "         # Forward pass\n",
    "        outputs = model(x_train_batch)\n",
    "\n",
    "        # Calculate the loss\n",
    "        loss = criterion(outputs.squeeze(), y_train_batch)\n",
    "\n",
    "        # Backward pass\n",
    "        loss.backward()\n",
    "\n",
    "        # Update weights\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    average_loss = total_loss / (len(x_train) / batch_size)\n",
    "    print(f\"Epoch {epoch + 1}/{epochs}, Loss: {average_loss:.4f}\")\n",
    "    \n",
    "    # Model Validation\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct_predictions = 0\n",
    "    total_samples = 0\n",
    "\n",
    "    # Turn of gradient for faster computation\n",
    "    with torch.no_grad():\n",
    "        for val_step in range(int(len(x_val)/batch_size)):\n",
    "            # print(f\"Val batch step: {val_step}\")\n",
    "            # Extract validation batches\n",
    "            x_val_batch, y_val_batch = (batch_padding(next(x_val_gen)).to(device),\n",
    "                                        torch.tensor(next(y_val_gen), dtype=torch.long).to(device))\n",
    "\n",
    "            # Forward pass and compute loss\n",
    "            outputs = model(x_val_batch)\n",
    "            loss = criterion(outputs.squeeze(), y_val_batch)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "            # Compare predictions with ground-truth\n",
    "            predictions = torch.argmax(torch.softmax(outputs,1),dim=1)\n",
    "            correct_predictions += (predictions == y_val_batch).sum().item()\n",
    "            total_samples += y_val_batch.size(0)\n",
    "\n",
    "    average_val_loss = val_loss / (len(x_val) / batch_size)\n",
    "    val_accuracy = correct_predictions / total_samples\n",
    "\n",
    "    print(f\"Validation Loss: {average_val_loss:.4f}, Validation Accuracy: {val_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
